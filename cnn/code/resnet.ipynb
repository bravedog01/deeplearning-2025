{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a327d6d0-cbf2-4767-a8a3-1c3a7bcd6b3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd0b54c-edc7-43ed-87a1-ada988a487d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb97a99-85a3-45f3-a388-7cc9f1f89461",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_set = torchvision.datasets.CIFAR10('./datasets', train=True, \n",
    "                                         download=True, transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR10('./datasets', train=False, \n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, \n",
    "                                           shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=100, \n",
    "                                          shuffle=False, num_workers=4)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "897398d3-2fc2-4cb1-af0d-7936d030bd6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAACwCAYAAACviAzDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSKklEQVR4nO29eZAd5XX3f7rvvX33ZfZFMyMJJJAAsUkgBMTBthJMHBsMSWwXieXljV8nkmPQr2IbOzhvnBBRSVW8pDCuJA44b0xw8GtwjGMcIgwYRyBQwCBAQgIto2X2ufve3b8/HN/nfI+YQcLiCqHzqZqq7nnudD/9bLfnOed8j+X7vk+KoiiKoihtwj7RFVAURVEU5dRCXz4URVEURWkr+vKhKIqiKEpb0ZcPRVEURVHair58KIqiKIrSVvTlQ1EURVGUtqIvH4qiKIqitBV9+VAURVEUpa3oy4eiKIqiKG1FXz4URVEURWkrb9jLx2233UaLFi2iSCRCq1evpq1bt75Rt1IURVEU5STCeiNyu3z729+mD33oQ/T1r3+dVq9eTV/+8pfpnnvuoZ07d1Jvb++8f+t5Hh06dIiSySRZlnW8q6YoiqIoyhuA7/tUKBRocHCQbPs19jb8N4CLL77YX79+fevcdV1/cHDQ37Rp02v+7ejoqE9E+qM/+qM/+qM/+nMS/oyOjr7md32QjjP1ep22bdtGN910U+t3tm3T2rVracuWLUd8vlarUa1Wa537/7MRc+ONN1I4HD7e1VMURVEU5Q2gVqvRl770JUomk6/52eP+8jE1NUWu61JfXx/8vq+vj3bs2HHE5zdt2kR/9md/dsTvw+GwvnwoiqIoyknG0bhMnPBol5tuuolyuVzrZ3R09ERXSVEURVGUN5DjvvPR3d1NgUCAxsfH4ffj4+PU399/xOd1h0NRFEVRTi2O+86H4zi0cuVK2rx5c+t3nufR5s2bac2aNcf7doqiKIqinGQc950PIqKNGzfSunXraNWqVXTxxRfTl7/8ZSqVSvSRj3zkl772bXd+H86jmaHWcTjiQFklfxDO3dJM69gK4W6LFzEOMtEUOst4bg3OHc839wyEoMxnkcu+iGL2PLd1XLfw/vGuYTjv6V/UOr70irdD2YpVK0xdIwEoC/sunCdipn7xCL5rBqwGrx3WVfgiN9mzWEEs89llLRK2vga2ATFb4L999Raai40b/z84DwbnHqqynd1qpXU8OY07cFOlHJzvfv651vH+vXugLNKVah2/8+3vgLL+zgE4P7DvcOt4+84XoKzg5lvHFbcMZc2sKTszjn5S5/SMwLntmrYLJOJQ5kVMP3uiL2fL+MyHCpOt41cO74OyydlXWseOjeO+WcXzfaPmb/dPjUFZ1TN1veqyDTQfmcv+tXUcEXM4ysZvMIBtFwuKHdOGaZMmTgMKsvnue3Uom85l4bzO/icrlPCetmXaNh7BuR+yzVz0mnj/SAzv6VtmzOayOC+zWVOfcAjvkUpHsT4hcyNPLOcZ5vRnk3wO/Gy+UmodF8vYeF7DtN2uFyah7JylS+B86unfpLm4+5t3to7dJraHHcB1IwTrKpbxtaBewzFpibHvszU3GMBnjiTM/J6dnYEy123AeSwSe9X7ExHl2bywSK75pn/ESki2hb8pVU2bhAK4rntkzkvlEpRFHJwzkdDcewo+HOP95TrKTz1R+f+9/oY573G0vCEvH+9///tpcnKSvvCFL9DY2Bidf/759MADDxzhhKooiqIoyqnHG/LyQUS0YcMG2rBh/v94FEVRFEU59Tjh0S6KoiiKopxavGE7H28YTbRf56eMfT8QErYvB9+tonFjE3YDaDuN9Rr7eqIbo3IqFbSxBcrMd6SC9anXjY2vXqtCmecbe6RLFSibGs3CeXHmQOs45KM9csmQqfuSFWdCmSPsiBPjh1rH+SraWSslU4dqDct6F6BPQ3dfT+s4aGG7esx26Ak7oiVsuXbg6IZcKISfs21xHSbd63lo53WSpp974wuwPrMROO92jD077aOd9bmdz7eOn9/8X1BWO2M5nGfLpi3rs1koi9mmfuFoDMrszkTrOOnjmCxNYL/bJTOeKiUck3WX3wN9IcIZ9A9ZkDZt0DOyFK/D+r1WK0DZZG4azot5U4dXJg9DWdMWThfzYHPfCTFnK26dFeE1fRfHbDycaR0HPRwvXtO0T62Ocy+dxjFRahh7v+tjfcqsn5PJFJblTf+4dRyTlTKOra4u0ycFdwLrw3w1Uknsu1IN+z0cNWOm0SxCWb1u6p6K4diySPi81Y1PSDycgLIJ5pcUsPHvqlXpyTA3NlsbfCG9bfnCV8M166iU6eZ9GRDrQsASvhJsPQyFsZ/530p/h4jwtYlGzd96Ljr0BJgfWzKJbVdl/iDNOo5Xx8G2DAbNdRtVHKPcA0Us8RQQ/iHWPEusNc/ZkT6KvHDua75edOdDURRFUZS2oi8fiqIoiqK0lZPP7JLBkNRExGxdReJpKPNtfDyryEw0hNtqnd3GfHHG8vOgLCvCsCb3bG0dx2LiHmwLzhJbgr7HzRO4hdzd0wXnPCQ1V8L7P/T977SOnfpaKDv/PDQH7Nlhwj5nZ0WYZ9Ns19UbWJ/p6Tycr7zYbDv2Doi6Bsw7bECGzInQX0vuGc6BTIjoi21ZbmqRUr7wySBuSXZ2duKFWfhqRIRHZnwzRmqHZ6HsldJ2OE/2G7NUJoTbu17FbMfbQTQN2kxgr1pBM91ze/fDeSVv6uCIBgqzqRyw8ZkTeTT1+KyFHAfHb5Rt40dF2GsmLUJ/F5nN4MOH0OwyWUeTzXyE2PZzU4S1+2Q6RZrwyhUczwXPhIFmEhkoc5k5NCye2Q5gx9cKZuzLkFQe1thsYDgmN5FM5HHOjj6HbUlDpn49I8JEw9amWBznS83Heek1TXulw9jPIZeZmbM4Z0dH8TrxflO/TBeujeWyGWvnnIdmzHrx6PfjuXkgKEzkXkP0O5g2RAgoO7eOkDrAtuR/mhJmslLVjJ/AERlYhSmXjdHl514CZekeY6rM5XCdKOaNWX7/nlegbMX5K/GOrO5P/vRhKJvJmutIM5RtzX8+F75UQBdmFx5WfpTL9jGhOx+KoiiKorQVfflQFEVRFKWt6MuHoiiKoiht5aTz+egYwtDSStHYVhNdg1DmBTNwXnKNHHRHCkOi4jFjL02G0WbeN4TKrKm6CcVNxbqxjNkVXQ/9HYoFYwf3xHtfRxfWtVBk9n0h53toj8n8e/937ocyR/g/BG3uf4A26lLF2FmDQWE7raOR79mnnm0dr7rkXCgbGultHTel1LmL9XGFSXYuqlUMKbSEnTPE2kTaQHkIWVCEk4WFrD4x2eSQ6JPzzj6XlWH75Evo08DDqptC/rjEQlLHnt8FZc2msW3HkxgOmRVh3K+MGR+QkAinTQbMuSPCTLsKeN0ke87uKM6DmMP8BkSzNoVvRNUyNvNFmYVQVp9G2fb5mJ0xbdlooN8LH/pdPVjXmvws86nyRRsEWei2GOpHhMSTZx7cbcw9n4Q7E9lBFnIpUjScNoK+au6kWScqFlaolmDrRAB9M0JhXAsaJdMnCXsIyvxCpnVcyooQ0An0uYh1GH+4Qg5DdmNR0x6RGK4h2WnRdvPA15im0J8PirDTZo0vFFIynZ/jdSzp75TKsPtj29WY9ID0+RgYQv+my9/x663jZKYDykJhM79qVexnJ2Tq+ra3XwFlUTH3Xn75ZXYP9E3L5c2YkN8HcvmzmM/HfJntpRuHJx07oNmPv9OH7nwoiqIoitJW9OVDURRFUZS2oi8fiqIoiqK0lZPO56NRQBtjwDW2KMdG26knJNS9pLFzxpJoRwyFjG118vCzUNYh7Ky9Hcbua9toC6sw+eWAsM1FIibuPuBg3UYPTcG5bRtbZnc3xtZHgsbHYvdujB2/61vfhfNzWCx5XdioPaZhEImhjHNExOHv2rmjdRyL43MtGDL1qQup81lhM89Xjs7p4/999//BuZQQjjEfnUQS7esZ1s5dnahv0DuI/jsx5hsQjaFOQjRj7PKFCuoQeFXxXOOm/yZmUONhqmrGbG4KpbSDZXPdopBBL0fwHvuY/oRfxz5gmdUpLNoqmsP/MeJMnvqMfvQTsChr6lNC239A2N65BEZU2MEH8XRecrPGnm0HcJBGo2Yclopo3/d8bINgwMzLShmlrANBM0/DIgW5I/yA+rqNLX5iGv13QkzDJS76p1I0/eOE8R5+BtvSnTHj8sB2XAvii0wbdKSFvHsVfS4ibqZ17FV6oSy334xnKyjuEcHnajbNs0wdRH+mOJvv4Sjev1rC9XgeFwMKMF8ET3xS+m2FHL7GSr0k0z6W8DFzRPqCVCbTOq5JyXKmLZLqwra78jffB+e9g8af0BZ+JXXmt9XVhe08PGT8A6X/xYsvoP9XImHG3ZKly6Ds8EGTbkNeR57bTHdJtp3H207sPVjCrwO8bjz1+VAURVEU5SRHXz4URVEURWkrJ53ZJdDE7e9Ip9k2TgjpdUtkpAyXzfZq2MVtpI6YCW2yxfaTE8attETKbI/L0C5iWRVtEdPnMT3boINl8a7T4DxfMNu042MoXX3ggDlvCMnpHbv3wnmdZWpdcS7Kxrssk+Xe3QehLDCEpp5izpgLHvwPDKM8fcVZreP0AG5fNjwZCkdHxd133wXnISFLzmXA4wkRLuqam8TFEL/wklVwfsUla1rHB0dHoSx/0GxRFmRotNg2rueyreNcFiWWx1kb2AE0Xbhls1VviShgCqIZhlgGUUtYr3g25aqNW+P5oAg3ZvLifd0oOT3B+nmiPg5lERE2XZs1W/fRcZwj3cMYgj4fjs3CnUNY93jUtEGtJkycJSHJHTGmlmYQPxtyTN3r4rnCwjza3WFMc46Y3qyZqVjHurq+qU9Ibo1nMGTW6TXz29+P93/6x9nW8YUNDGG++NK3wXl2zJg9dmzFOdzBzMzV6BiUVeJorg3apj6OCPnmCa+nx9F0kYmgmQODwxFuAbCO2MbHAc1N1gGRCZtnoxXL3xEhuzxEtFDEPiBmnjzrvAuhqLsPs3pz24YjzHbJdJqVyTXfHNeqaKLq6MJw2jPONBmmUwmc+9uffbp1XG+gSdETkg4QlitSCcRYdmNL6KtLg7jFv8tsNbsoiqIoinKSoy8fiqIoiqK0FX35UBRFURSlrZx0Ph+lKto13RKz6eVE+JaL/gY2C63qXnAGlCUzTDJdSCMvWYj+D11pYyeXlrB80fhR7NmHPgQhnq48jmnXLZEK2vVNecARUt7spnYQ3x9lSunJSWPfnppA35EZFhK6/bnnoKzjqivhPMyM3w8+/BiUnXPx6tbxO6++Gspkuvto5Ojed8f2H4Lzs85AWf2ejAlVzHRjOG3uoHnmyp4DUFZlcstERGMh0yf5/egLsDtsGjov0qePCPnuDtu0e6WGqd5nysbWG6uhvTbIZNoDURECKvxc4kHTB5bw4yjlzdiuW2gDdkW6AO53MzuDVvp4ytjMu0cwXtYRPlTjzGeoXMN7hiJHH2vrBMxnk3G0mQeZ70ajiTb7iPCpqldMOwfDWFcu7Z2vYv/092D4dZlLe9s4T92GactmVfifMX8D28I29x1sn0Sfea7uBeh38+h/mTFy+AW0/Ttn4Lrljxv/ooN7caz3v8PUJ084tp0uDLUte8aXo9nAVS0WNtep1bHtOkWaivl8PlzXPJcltOl9ce6y+RYMoF+Jx8ZhMIRjQK43DeZnIX0uFi85u3V83gXo8xFP4HdAkvtg2NKfKMKO8Su1yu4ZEWHA6Q6cIzMsDD9XwLHe2W186Wzho5TLoY9ZdXqalWF/EfPzSAi/EvkdxMN0fV99PhRFURRFOcnRlw9FURRFUdrKSWd2KdfRBJEJme3DysROKKtXcMspkjShuP2no4Kcz9RRax5usQcjQimVqfGJiF2aYZlrcxUMS+tKmJCsuiu2GcVWcL1utigbIqTPYyqiQRkKKK4zxdqguBBDkbnFplHHLeRUBrcdZ5jS4/gYmkQe+o//aB0vO/8CKOtfhAqadfEscxEWCqvD/Zix+OyzzZZpOI7bmTtYtspIE7dhU3HsywYL3Y4JMwcx80WtjAqV5TK2V6NpyssWmvuyWbOFGrGFKicbB1KBMSDCBi1Wva5BNDWV2N+WyzgGFg4sgvMQC5n1i/gcsZS5yURlGsrCadwmjrPPjh/Ee7rBo19a7BALDYziuAsF2LzE5oGspEREYRaaHBbb3/GYMQ/EkhgOTmJbf7Zo+qReE6Zctm1dFNlfKWXuGYuJ1LmEdQ3FTbs7KbyHw8ZoJIBmnxe3bofzWs3Mp1gGF6NCxMzTQBrraseFAmyFrWliUYskzSJTLeOCE4gdfT+7rqmrVAn1ZIpgZtBuiuzF/G8tEfYaEIqe2VljCGo0RJbxPDNtiPtHY2FxzrIZizj3ZMKMn0IBv59stob4vsgKLVR4U0kzfgeEEvPKi41SdSmPxq2iMNEcHptsHe/dh7IIM7OmjERbSWkKsLQcZTbyY0F3PhRFURRFaSv68qEoiqIoSls55pePRx99lN7znvfQ4OAgWZZF9913H5T7vk9f+MIXaGBggKLRKK1du5Z27dr16hdTFEVRFOWU45h9PkqlEp133nn00Y9+lK699tojyv/qr/6KvvrVr9I3v/lNWrx4Md1888105ZVX0gsvvECRSORVrnhsLFqEPgUhJl1dLqEtrFlDu12k39isQ3EMESuzML2hAbS3LViANuJq0dhPK8KHwQkbW28yifdoslAz4apBNRG21+ChZiHspoUjI63jg/vxxa5WxRA6buuOx7D9eahto4EG9V270X8mN2uytjoBfGfd/aLJePvAv90PZVdf/1tYn8zRhWAmRAhfXLSly/xeXtr1EpR5zBEmsRB9RSpdeJ3pGJNqFuGZvczuXG6iTdgW5wFmh47Hcdx5zAZrC7n5GGvLpgjcDonMqF7RlL+8B+Wxy2xMNqTdW4yJsGfGU28c+6PCfH+KwgelKfybfB42LJ6rkmWZfQdPp/mIx03bOWKs1ypmHsTF+tGsY/vYTPJeZpR2mP+ML7Jdz86gnd532X187MsmDzWtCBs+8wexfLTn+xa2ZajT9LsTxv4a6DP+PB0ZrGuhgL4bQTZGBoYyUFYL7m4dN4LoFyASdVOUZdm2XRkGa47zRfS/aJSzdLRMFUzb9WTSWCjmU5D1X6Mu/GWYn0elgn3XqOHK2mTjWcoQdLIQ/Z4e9KGKREQDsVD6kAjv5de1LZwk3CcvKMLjyyIjcDRl2mRoCH3lGjX2nZPDENnDh3HdSrJMvgHhO+ccNGO7URfzuyYyFLOwZaHEflw45pePq666iq666qpXLfN9n7785S/Tn/zJn9DV/6P38E//9E/U19dH9913H33gAx/45WqrKIqiKMpJz3H1+dizZw+NjY3R2rVrW79Lp9O0evVq2rJly6v+Ta1Wo3w+Dz+KoiiKorx1Oa4vH2NjP8+c2NeHZou+vr5WmWTTpk2UTqdbP8PDw6/6OUVRFEVR3hqccJ2Pm266iTZu3Ng6z+fz876AOGG0FRaYZLjnoX3WjmXgvG/BotZxKITvXTGWzzwu7H3pKNoRU46xuZUq6PNRyhup20gQbYwO8ynIZ7NQVsyjLdciY1d0pObFyJLWcWEWNTcckWOay6If2LcHyvLMT6BT2GDLFfQTmJkxPh9hIeleZxoYD2/eDGVnXHAWnF96xRV0NEQTqL1gi+caO2SkpKVGic2ktCsi3XQqidcNZ4y0tdXYD2UDTWNrrgk/irjQkQiw8TSWQ32MPqbb0C9k2aOWaediE30IguKeqY5M67g+gfbaJSmTwj4rfEemSzhGy2TaZKqMO429aTMPXKGRMlnCMZpqmjYICd0G7hf1WoSCxg8nHMI04z5LiRAM4ZhMENq+KxWmfxORmi1MG0IYsF3hb5VmfjB10QaOY85HhhZBWZ75f1UD+PwT0xNwHq4YufP+1BIoWzxk/A8Kon8O7MMUCb5nxvrAabj+9S0146kudBomD2H9YiEmER7E61QK5rm8JvqglJq4FsiE9pzpnPHP6GZ+CUREwh0DZMmDUjOGfbhZxzkjlOGpyLQ00iKF/Vnnntc6znT0QFkwgE/SwdI5SHl1j2kFSb0Sl83pSATHUiyKbTkzY747Uilcjzu6jN9hPIZ/l+jA53r22edbxyGhg5LuMOtEVWgXNcOo1VNkmiW2ffydPo7rzkd//8/zo4yPYx6B8fHxVpkkHA5TKpWCH0VRFEVR3roc15ePxYsXU39/P21m//3m83l64oknaM2aNcfzVoqiKIqinKQcs9mlWCzS7t0mhGvPnj30zDPPUGdnJ42MjNANN9xAf/EXf0FLly5thdoODg7SNddcc1wqfHgM5WIHe812WDqDIbFlESY3MGyy08ZFps9kp5F1HuzCLa+82DLl4V1CsZdslh3SscV2d87sCO19ZS+U1UVW0Hjc1KEiTCD5IsvaKiTkO7u64ZxvlhXLYtuahd4OD2Pm3kRayKuz7LiLFp8GZf3MnLVjH5qB9u9HU8avOke3fRewxT6sCOWMskySGSGv3mQhYkEX+7lWwbC9fS+aUOXUy3uhzGUZZweELHpM7GNXmAR0bw1DvgdYWHe4hlv8NR6u2sSyah7DCMNps4V62Yrzoexy2/TXjukZKPuv7BScH/ZYOK2H7ZGsmLbLT4lQPGH+C1ZZO4vg8aYtg8nnptYwpoVCCcNpg+yeM0LOPCEyQ3ey8Zwt4Fivsv4KBTGkMCBMei6rj+/jFneUZTsNyTFhm7oGbVx7yg7eMx012/zJJu72unWTubtcxS3+SWGGmZgw55UgztnwlLmn04/9YXsibLlm7hMSZoUwy2rbkca6ZqeF5v08VJkUvAwZTgpTQoCFrNq2+B+ZVc8TpspAFEPpz75wRev4nPPPh7LBkYXm78QYkLfk+uLBgJDOZ+21YBBD+13X/J0nMsOWSrh2e57pS1eEO0cjxsSYm8Hvo+lpNPMW2XWPCAsm016pNH7POQ6ang7sN2b6qvieOR4c88vHU089RW9/+9tb57/w11i3bh3deeed9OlPf5pKpRJ9/OMfp2w2S5dffjk98MADx0XjQ1EURVGUk59jfvm44ooryBdvcBzLsuiLX/wiffGLX/ylKqYoiqIoylsTze2iKIqiKEpbOeGhtsfK8PBCOI/EjJ21Z3gEympNtFGXWOrhZgnt4JmM0SbJT6BfSUEYACdYeG9VSFd3dhoflJiMO2OS4IuHUNZahpoFWIhUvYl2u8PjRjMlmUYbZ5AG4LzBfBFcD31QPGbHdEVIaqUspb5NfcNRrHuISTMnZCpq6SdwlCNOSjwnRXr5LuZH4XsitJTlXp+aQf8Ha1rIH7OQ5zOnRAp5Mm2XEH5AMtQ2EzL1CTRwvHgsHLCZRdtpjcUGhhrof+EWcWx1Dy9uHS/sxuix3izz44ijXX5INHqxaNrEE35JEduYRzvj6EM1I/ybrJCxk8eED5Ucz/NhMf+eggjnzXSasRaPo36Q18S2HGdh7lNSrJCF13Z3o2+E38Dr+L5pk4F+lN0OBliqdyFPHbXMdZ0a+l6FItgnvWHTtjVR1elp0+/7DkxCmR/C+R6IGl+AYh39FmZnzLhbMITzJ53BNSVkmTEbEWO7wtq5swfv7/vYdvN7gJi2mxY+H6lEXHzUPIuY3tRsmv7p6UVZhne9D9M5/MY117WODxxA/7NDh0Zbx7Ua1rxcnoXz2Unjy5ZMZ6BsyRlnto47OnCdaDCnwIlxDJOW3x2RiOmjYgkHRa1m2tltYl2L+SycdzOdLSuIZQGm914oYN/lC3hPm40Ja25jx+tGdz4URVEURWkr+vKhKIqiKEpb0ZcPRVEURVHayknn8/GRj/4BnNdZTL7n4btUuYyG53rexEfHbIy7r+dMWY+Q4Q3H0UYcixp7KZcdJyKKxYzmhAwvBplgETHkeVjXEktnPjWLfgseS9ctOzBv4W/KZWPjazTxmQvFbOs4VEY7YjicgfN6w9iPyxW0144yW+psIQtluRn0oxBuJ3PiCT2OVAR1APyqKc8KX40K8wOaraJdsyG0M/q5QdkV/g8d5jqRERwDlSzaa/2AaeeQjf2eYv1eF/Hy+Zzx1UiH0G9itoL9FWP/K/jCP6TM/FMqNmof+EIauTtt/CjcKrZHkvlJDWfQnp4Q2h0BJj0eFzoJ3jGkWo84Zj5ZhI4lzbKpn9dAPZcJMdYK7FlsoTsSZz5UsxM4fqNh9IeIMNnrQFNoXrDzhIW6CHbd2PsP7ML5FI+g70iomWkdHzqI9Ykzn53p3CtQ1tkrZLeZLHgygWMiEDTXdYS+jiOkvvnElGnhw0zPpFTEtSjTgb4j8/p8sFsWK/jJhlj/gmx99Fwcz0k2fn/rdz8CZRcJMUubz0tH+p+ZClXFmuYKH5DNjzzSOo5G0X/n/3xxtbmm8E3zyLTrzmdfgLKXX9kF5wtPW9Q6jgsfmEzGfCfl89gHTkSkoiDznImk+J5hbRkUGiDcH4QIfZoqJVzvjge686EoiqIoSlvRlw9FURRFUdrKSWd26ezF8L+upJEF378LtyitJoZLDbKMpkMdGArXETNbUJ0Z3FbLl1H2epZl+5NxYDVmvhAqxVRnst8xYUaQMsENblYQctmHD5qwr5IwIwRd3L6MsK1Ft4FlHvtstYZb/I26kNNlMtxlZq4hwm1zGTIXEG0gQ2jnxMMtwFAAt0wbTPq8NIv1cWImDLWzE01olSheJ8TMIN4hNN/UZs1WbHE3bjs2qjh1goGMuU5TmGRYNtZQWUh7M1NGj9DqTxSxD5yDLDQwNwZlY1Xzt1XRdokgbq86IbM1HMPqUKRgfpEJ4TN2hXD85NhWdUaEVHexsfVaAtxcZjpgZaCsyDLO2hEhlS/mTEfAzNsOH8dhV9CEH3ohNIv19qEktsdMjE5BSGlX2IBu4HViZEwrZ6bw7xoNlNwvsazElRyuL719Zm268KLzoWxiBsdEbta0c28fmnZSGbP+BWw0K4Qd/L/TZ9lYqyJTdzBk1irLxjEqzWTzwi2cYp2azmGY50DGhPTKhKqJZKZ1vHDJmVBWq4tw9Vy2dZxM4rreZGuRLaQGHDFnnn9+R+t4+VkroMxi/8MHLPy7GkvF8ZMnnoCy//qvn8D5//5fxoQUi4mxFTPjORwR8gqOMO8HTH/5JMxiLIQ3HBbh1mIOW6zDCnkcv8cD3flQFEVRFKWt6MuHoiiKoihtRV8+FEVRFEVpKyedz8f//eY34HwRk5LNC/na3gyGRwaYJHcxiz4XxKSiZ0T6dleE7RUbxkY73UCLdorZFYMiNJGH0zrzlBEJfxHhVxJgsrcyJCwu7PR1JqHeqKNt2WKy8XURutmood9CrWpsxlUh/Vtnab+tgEgzLuyIo6+gxPFchMIYPuZawkbN4vZcYfv3WZp6O4n20YhIdc4luqtxrKvD6l7K4jMnz70IzqPLzm8dT7/wDJRNP/ZA6zhdwT7wfFOf3ir2QUzI+juT2dZxxRU+MAVjp2+U0WbfPYiy5MHODDvDcWixsda0cEymbTwPFY1PQbyKfdDjmHZ/rR7P5k2beMLXiEv3xxJ4/54QyvwvjZjUC0OBIbyOZ/woXMKxtSC5CM7duvF7mZrBeVBg/ZcbR+nzXCXbOg6KUPqZLK5N+w8bn50S4ZgMZTKt496eDJTN5qUktqnPTBHbZ/kC4+8UFWG4tiVCmn0zbz2x/nHfsIDw+ZBpGeYjlTZrYz6Hvmo5Ibc+wMaoRVif089c1jouCv8zX8TyR+LGV+KlXS9D2b49xkfwktU4n5tCwvxXVplw2t4BnE/Tk+PmRKQ9KDCZhLTw83OEf8hArwmbLhexPcoxs/4kYrimhcPo82GHzDM3RKh4NGa+E4sF9CW0hXNNgIXiRkTdjwe686EoiqIoSlvRlw9FURRFUdrKSWd22f70I3A+2WG2uZJCwW7x8IVw3j1gMr5WC7jt57tm+5KHjhIRRVO4vTvAlOBiTdzO5OYTy8JtLIuHvdZxK9EO4HsgN9lkRIhYPmnqPnv4AJRNT2MIpsXCKms13PJvuHxLDrdP61IZlJ03xdZ4PGG2/UpCKXD7M8/CeY5tW+PmJeITbhdmcxjqVZ4yyrKO2BKsR8ywboaxD3psNMW5TLmv3o3bmc7yRa3jjv3YdtXl58H5E/1GeXI4vRrKQiwEvL4bVQ69gNniD/q4ZRz1cTyHm+a5GsLs4kdNHyTFNrUrFHpnYuY6E5YITWTmLE+E4qWEiaavaXowibekegTrNx/ZvJkzsTCaDjqipk+sLPbB8sRZcH5ayJwHaxhiPTrOlJDFdne1iCH5QdvcJxTGJdKtmfoVS1if/KxRSW6KdaFWx759cTfLjO3j+E30mDExvBilBerCHDqbNeaB/YdxXq5yTdvFCNvVEuHY5JnxU6mgiTESZpmXRYbkqjC3zce6D320dfx3f3c73l6MLS9sxuwlF6+CstPOXN46fnn3bihLp7Hf+9maf9e/fAvKulgY/q+tXQtl+/bjmDj/EqOcOjCIphUuvZAX5qPJwyY8/uJVK6Fs9QXnw/lQr7nugVF8rkLW1KcpQo+lcqvH1k4eQk1EZLPvFRnu7ByhAGv6OpHG78Djge58KIqiKIrSVvTlQ1EURVGUtqIvH4qiKIqitJWTzufD8dH2Xy8z+76FvhG2kIMer5m/jcTQ7tsRz5hrivCxLKH9tlIy9ttSGW2wOeab4Aopce4PUhPZTZsNtAmHWKZNS2QbdFmor7TBlpp4nTLLjFqoCPsf85WwLLTdVoTvhsX8EVxhzybPtGUoiO+zhw5ioGWeybj3LcNwSE4sgeGQZRFSPMZ8Ps4YWYR1ZW03un8UykoiLHcBa4OwkCJ2y+azVgzDIXtGMKPpmSPGtpyZzmLdO8y4dBMYFucHmMw2oQ8BCT+gjtNNKGno9AVQFmT+O94hDAEtBoX/DAul3OPjPW3m8+FbOO7yYowOsHDaUAfKmectIc8/H655zojwFbGYr0SvPQBlXf4ivOeM+VsZHh9ImVDb2akslH3/R5vhfGhBpnV8wXnLoCzA/LhcMV5yZTO/Eins5+lpXLdmimwuBnFe1iaMz0UogmULhjNw7kdNfboXolZ+Im7WG68pfLqEz5nLMtmm49iXQRZiHRD/r9pNXGPn4+WX97SOzz4HJcp3v4xhsDylRSSJfhwPP7aldXzuOedAWX8/SuUvWGDOpZz4Mz97mtUNfSxGRkbg/M5vfrN1/La3XQ5ly5aZMRIW/oJLzz67dTxx+CCUlbPoV1Jma2NQzP3Dh0zbFYVkQiAiJCXCLCuz+O7wfeZfFcN+dqXcAwv199+AfQrd+VAURVEUpa3oy4eiKIqiKG1FXz4URVEURWkrJ53PRzk7AefhjLFTRbswXv6Jxx+F82LR2NcdB234KSbDnRfpnStSH4PZvj1XxlGb97me7m4oKzLJ3NmpcSgLBzF4m0twuD6+I4Zjxh8iJJ6jLmTIi0yTo1LFzyZZKuaZ2VegzIuJ1PNMNl0+czFv/F4S6TSUeQ20/VeyXIdkbp+PgSGMpa80sA/KrA+EpwT5RfMbJ4u+K9N1PO9bYOrQgUXU/OnO1nE1hvbQvvNPg/NLzh9uHR98aQ+UlfNG0yEZQpuwzWS4LQd9M1yRKvsAa4MDM9NQFmVpz+MN7J9EAPuywzLXHRRy/NxmnbOEP0gNfX2aTKre60M9inCUtRc+1hH0Z4yGQDCCNuoGkzcfXID+F5nocjjPs3EZiAq/BebLMrp9B5SNHsL5fpjJ2Es583jUzK9qFf2QKkWj93DBgqVQFnLQN6zCmscWfjdx1q75otDc6MXGvOI3jT9Rog+1i+yQ8SGo1/HvGmIOh5mvTVz43XhsrjWEj0dPJ/Y7rmrIinONNs57Fl8NZTfffBOcL1tm+nbfXvQbG1pg5toK4fNx2uk4L6emjf/T//nTP4Wyf/iHf2gd79j5IpRddBFqcvzWdde2jjNp9C0MBcyYffgR/M65jPmH9Haj70qzif0+PWPkzmemhD8Ik/wvC9+rjgx+7/G+dRyc3w7rWymNbwmfjwRzJQlOohT78UB3PhRFURRFaSvH9PKxadMmuuiiiyiZTFJvby9dc801tHPnTvhMtVql9evXU1dXFyUSCbruuutofHy+92FFURRFUU4ljsns8sgjj9D69evpoosuomazSZ/73Ofo13/91+mFF16g+P+EZ9144430gx/8gO655x5Kp9O0YcMGuvbaa+mnP/3pcalwqkOG05rt1MnZKSibmcKtolrFbBufcxZu1w2xkKyf7t0LZRURFhvg4a1iSzkaM1tgg0KG9/CYMTns34ehZQ0RosV3N2XIYyhhTBtVscWeFeFbVRZqm0miGSjApHazWWyrSnZu6V0pG1/nJhCxFd30MaSvDNdF2WTO8rPOxL/LCVlpti05PpuFsnSShemKsDRfqEqPzxrzxcJZ7Mx4ydS9nEczx9i9P4TzKJPLruxGE5bFwiybIqsuMcl0S2yDuiKiORwxY/8MkVXXjZpxlxZmw7Hd+A9CxTXPFfBxCQg0TN9GxBa718DGiwybcN+hlZjKoJY0pp3xx5+k+cjNsjoUslDWb5nw2nRwEZSV8tiWO14yc8oT8ynAMvROTKJ5orMfQ3h3vbKrdVx7GcMjU8yaU5rFMRFkmWLlVnhuFsNg0ylT7kVwPlVKzDxMSLGJ83uias6LZUytEAqyUHoRemyLORwNMlNPCedaKm3mU1h8ZRSKON/nYzZn6vqO038NytZ95GNwHmaZWS8892woW77crA2+yPw8MYlm+SqTQuhMoUn4XWtNHWJJDFeVobadnWbuySyyPMv4oz9Bs8uuF42Jr+fSi6Fscgq/r8q5bOt4Oo9zOMSy0Z55BtbNE30ymzXrTbmC/cPdAgIBnCOeyAhMvhkj8pmPB8f08vHAAw/A+Z133km9vb20bds2etvb3ka5XI6+8Y1v0F133UXveMc7iIjojjvuoOXLl9Pjjz9Ol1xyyfGruaIoiqIoJyW/lM/HLwS1Ov8nQc+2bduo0WjQWpakZ9myZTQyMkJbtmx51WvUajXK5/PwoyiKoijKW5fX/fLheR7dcMMNdNlll9E5/+NxPDY2Ro7jUCaTgc/29fXR2NjYq1zl534k6XS69TM8PPyqn1MURVEU5a3B6w61Xb9+PW3fvp0ee+yxX6oCN910E23cuLF1ns/n530BqdbREB5PZVrH6RSm/S2Vhb2LpwsXEuE55i9SKaEUckGkSY4z+eFwGO3ODpMXn5o4DGVTE8bxNhhEe5sVQptamNlgeTgoEVEsYeyP+/ZiWGd+Fm3CTSa33pNBO2+Th68Kf4OaaB8uFR+LxeYsqwkb40AKQx5lqvG5ODSGbVcSPh+exX198JmzDdNf8W70EVrSg+FuXs581iNsn87TF7eOk8IeGqqJsNim6a+u09FGnWQpwD1ho66UjP+BPYZS8H4OfRPiixe1jnvPQnnqJrPfphvoX5B30WfpwAvPmZNoBsq4r0QigW0VDuBYH2Y27I4FKPfuHoPsdr5ofCd6e3FedNnGT2nP89g+hw7sg/Of7TC+LU4Sx2hfjwkJDTJZeCIiNyDClnkoZUj0V8PszAZEGGOQ9UFdhOfXCyh5v+o8Y7efqWI/79ht/lGr1UWqeeFTVTtkxn5PEP2rYiws2PJwbMejQsY+b+ZBtY7jxWLuK5aP4176G8zHksVmPn33O9+Gso9/4pNwvm/U9HVPCvvy2WfN+BXKAjQ0gt8dv/Irl7WOSwVsu8kp4x/Smc5AWT4nfOeqpk06OrqgbJr5blQqOPciLH1DIIBt1dePc2Z3gY2DEPZPPGHGbECsIW4D+z2VzLSOs0JqoMk+K+XmazXsd+4fErSPf2Ds63r52LBhA91///306KOP0tCQ+WLs7++ner1O2WwWdj/Gx8epv7//Va708y9v+QWuKIqiKMpbl2N6nfF9nzZs2ED33nsvPfTQQ7SYvckSEa1cuZJCoRBt3mwSNe3cuZP2799Pa9asOT41VhRFURTlpOaYdj7Wr19Pd911F33ve9+jZDLZ8uNIp9MUjUYpnU7Txz72Mdq4cSN1dnZSKpWiT37yk7RmzZrjFulSliaQsNnWH+pD80RQhKg6EWPaGDt0AMpmJo1JJCmyOsoMtLWKMQEEbdyGLOfNdvN+oU5Yq5otuVgUd3sCQs0yXzT3cETm2kULzZbtzue3Q1mzjtt+ts22W13cnvOY2SVg47YsBbDtgqwO0SiGEfJsvTIk6+xlqEIptwzn4r9/hs/VqGLdm1VjBpmawG3zMstCPDSMCoyre3EHbuT0M1rHYzsx/Ll3oTE7LBDmCUtEpRHbwrRtbLsEt0BYOF5yRRPi3LUMQ+icBJqMnEFTHhzALdumZ64b9rFyw9YFcL6IhadbDo51hymeJoVpsFFGk9lLh80cOixDA+toxpsPJ2rGYVcGTaepaqZ1HI7gnIkksC1PX2r+GcoW0HQ6MWm2xsfGs1DmB7Cu3UyJslbBtnRYJtuoyCZaZVlJi8I8svIinAf9C03Y56FZDHOfnDZteXBWbJsL86M9Zs4LZRx3l6wx5oGsUIauimkYZNlPw1GRUbrK+t1Dc1LYRhPWfGzd+kTr+MmnMPz64CGs3wWrTCj5zDiGO9eYSYuH3RIRrVyJ4fs8q3VWhKDvPWDGbzCEa9ryZUvgPMraRGYg5/M9FMIx2t1jsl+/LELeD4yiGZFnlQ2K6wSZWb5awbVQZiiuNc3YE19PkAW9UMD2KBXQ/MfdDWamMSz4eHBMLx+33347ERFdccUV8Ps77riDPvzhDxMR0Ze+9CWybZuuu+46qtVqdOWVV9LXvva141JZRVEURVFOfo7p5cP3XyNJAxFFIhG67bbb6LbbbnvdlVIURVEU5a2L5nZRFEVRFKWtnHRZbSszaMst+sYGO+GgbXDmEGqLuDwEUezihEI8xFDYwYPiHY3JzpaF3azI7HZ9fX1QZrEwxlIFbbfNItp2eZjwuAgpdFgG3HoZ7XTSr8Pl6XF9tG3zbJW20Im3hG8GL20ImyffEYvH0QacSKANP3KUkU1WAO3OgYgIBWbho24Yw9JqLBPp89tR6vzQOPbXQiaBn9+P7XxozNiEL2xgezhl4VvDnkv6tXA3D8vCKVdhIcMlER46cvmlWNeFxg6dFdLeeRYKyMOriYgOT6BPQZOFCe96/lko42O2lECfhgmRo2nvfpNtdMXZmK4gETt6X4CubuP/4AqfpVrJ9PvUwUNQ9vI+/OyChYtax3URkn/gkAl1zeezUDayGMdoT4/ph70vY8h3T69pk4CL/g+1ppl7HSK1QscilHDfuv0nreOZIvqU5Wus/0IYsuzaeF4rm/NmGf22xvaZZ+4dwDWt4WLbVViYpW+j/0OZ+UrEIrhO+NKpYB4qbM1bvgwzFO/buxvOn3zy8dbx+665BsoKzB9u+/MvQFlHGsPDzzvPhL2HxTqxc5e5Z1qEle/bj98lHRkzRuX3wywL9echuURE48xfZUqE0udEWogGW6tj4h5FPkbEd1dZ+Bc5juk/18XxkuWZc0Vm7KLw+aiwZwmFhE/gcUB3PhRFURRFaSv68qEoiqIoSlvRlw9FURRFUdrKSefzERIStTw2edeLL0JZU8jORiLmb30StlMWy96oz58mOsSkb0NCBpdbxgpC+4Cnoq8L22BJpLF2mW7DoX0vQdnB/ahHwQkIHQl+z2IeJZ65XTwiUpB7LvpYcDNjTdgYuc5HTGgxBMT7rX+UstsRoTXA70FE5DA9kYiQe8/PGn+D6Sm0a07NZOGcy7g7TbThnz1k7PbVA6hDQLOib1n8vExXDng4XuyY8TeoCbnjndZWOJ9kMg71rgyULRxeaG4h2iqXR1vuxJh5lj270dYeYCPYFfoBZZGuIBw0z3L4MPpjcL2DgYFXVzf+BYmEabvqJPo+NZjs/+gYtvlUFiWwZ3LGH8z2UfPC8syz9PahFs2SM7B+kbixmU9O4viNshQF1QK2cyxl7hnpQL+bp/f+DM6nPdMnRQvbteGYezQt9F2xLJyXEZaGoasTfTWaNXOdoIuaMaUSXteJmGdpWKLfa+yeQg+oswv9gtC7CFm6xPgs2UK76MILz4dz7n8wNLQQyoilGfCEj1tY6CfZTK9ISp+nmV+F9APKibHVYJpIQVF37mNVLOB1Xn7JaHu4DVxfHAfXAtc3z1IRfkA1pmvkiVQY8rzI9Dmk5pATMueDYl42u1E2nj+XZeHadDzQnQ9FURRFUdqKvnwoiqIoitJWTjqzS6wDtw/dutkaqonwx3BUPB4LNQ0FcfuQywvLbWsprua55p5NscXOMwHKkEeXheIVhfR6Q2z5Q1kDt+B4fWJRDMmKC2l4LqFbyGH4WIBtH0bElr8twtJGWKbhg4dwi31m2my2Srn5kNAhtyE7LJpLOJEIbo3LPuCZdHmYNBGRw7Zaw2JrM5DD9pmcNaaoehm3LwOdGXP/vDA1Cflwm9XBn8fs0vBwG7TOzAE1ISHfEKF4VSZn7oXws311ZiIqoglvZgY3w4ssrLu3F+Xnp1lfjo+jqUkmgOQy+/zviIj6+jG0dD5CQdO3dQ/n7Ewp2zrOCU3wFEZHUr1o+ijuoDkgaZtx0DGI4y7dhXNvOmfuGYziPQMJNhctNGMG2HM4SbFOpXBt6h0wdbCncCztGWdZUgPYz3EcznTGUtPOMuiV7bBTyMZnTsXTcO6yNa1Rxjkbi7C6EtbVcY4+pDrKsgDHRfv4njCfdGRax6P7MHP3GSxMNy6eo5vNWSKi0VETDj4r5tMVv3J56ziXxfV4YhL7dnmPCdndJ+qza+eO1vFpCzFFQpSZoZtNfEaZoZ2byC2RYTsWM+tWUcxvLutPRBRgQzYk0l002D2rwgxlx3FtCrDvROnCcDzQnQ9FURRFUdqKvnwoiqIoitJW9OVDURRFUZS2ctL5fEi7WZ2lV5Z+AokYhp7NTBk7Xq2Gds1jwWYS2V4V7cUuC3saEHbvELP/5fPCZ8Cez3dEpJNn/g7xOD5jbw9KuvOQNU/YVUOWuYcv/VwI6eoyYVhcTpiIaNo3f1sT9sexafQbCLDnXNgljPYMGc4mCTC/DvlZLocfFr4sQSH/HmbtNzOD8uEzTdPOL9l4j2AEbeg15t8jpb091ppV0bKlkvFTCIks9IN9GThPsbG2V8hKb/uJSVE+JXw1ZkR/lZjNOBjC5+rqMinAXRFuvWoVpivn/iJyjNosJN5tzj/X4syRwe7EeVCrmfDZUApt0skY+qCUgyx0XPrdsNNkEsd6OI5jNn+IzZkg9nOkw4ytop+FMidinsONYRqISgNTPYQSpk0yERyTA0Vj3y+UsG7VGvp/BcNm/BQmRdi/w9LAC5N9PImfHTtsnpmH+RMRpSPM9t/EMbF/FJ9rPhYyv7GImIcyfD/GQu3PXXEelLnM/8sJ4/jt6EAfkELe9EPEEesNWw+TMVwnSmUheT9r1oapCZxfA73dreOECPWNJ8xz8DWLiKgpQtn50jAuUhm4zF9R+rVUa/gdxL9KRFdSmV0nFka/m2oN6xNk8gtVH9ujcfSq+nOiOx+KoiiKorQVfflQFEVRFKWtnHRmF66qSETkxMxWVlyEFQUsfLcKse35usieycNrrfkUKglDmSLinsGA2XZr1HArkYcmplK47VgR2448tFRmkQ2wCshwKbldx00Schudb6Faoq3kPZ991mQ/rVTmVjidzWah7KU9qMbKw7cWLjmTjhYZamtD5lhhsmLbhZ4wc8Sl8iUzoUWFyuuufSakeOdkFspiYhxOTxsl1XwRFUUbrH1qFm7520yRtiOIW7ZnzOL2bvTZ51vHz+3Fdp2aNqaVeh37joeRExGl02ZrekHnAijrZiqHPLyP6MgxkWOKolKt0WJji4/XV6PJrFTRFC5JRa4kmxRqjWm8Z5iFCsZENtjcpKl7qhtNlUNndsM5F1mt27jd3GTqoxTFuR9j0b2RQQyHnJ5C01coaq7jWNjvg6ebcTiTxbHdqGAb8CzROw9iuHOcDedwBNuje1CEWQbMOCyXcBs/4Jq1Kp1EFcxDY1P4WZqbkYVGqdQO4FwLiczhpZKZQ7bIEt3dYVSB7QC2T1lIGESZ2bVeF+Y2tnbHEz1Q1hTKqXz96etG802CmZCKKQzx5qYLaY6V3zLcdNn0hRkTMmOLDNtiHJZKZgDLNb+WMGNftmvIwXnBzTlSSfYVkfX39aA7H4qiKIqitBV9+VAURVEUpa3oy4eiKIqiKG3lpPP5iAmJZ+7XEQ1hGc94S0TkijAxjrR/zUeQxTKdcdoiKOvuMeGH9TraTnkocEPY4vYyGWAi9N2QoaTcdyQknlnK4M4XssptjFJSXrYHD6+V/hf8Hkf4BRTQBusI2fa5kPeQPgVcUt0X8WT1prFnB4X0ekBkBY0GTVvGxWcL7LnGm3iPV4RvTZHJ49eExLzL/YnEc/EkxFURkjrxMmacdV/a1Tr2xHW4UdgOSMs7nvO+LouQwgkWRphKYdii7Ft+zsckEWZ7Tibnl+D2mR/OVA5lrWdZRtWGCG8OdOBY70gbX4BiDn0s8jPM3p4YhjI7KfyJkqYvO8I4L7yQGc+2j+0R7TZzpuJgNuVIN/aBz3w3KkX0oQoyvxLLRj+Bnn70KagUzHUckU7CcUzdZ6ZwHiYz2F+xRKZ1XKugvwrPxBwOoH9BOob1wZzESICF5PuuSLsgfECSCTNmMp0dUNZ05/bP8xoiWy/TmE8k0VfDY+uGXF9SEQxDbbK1vB4UawpbNzzh35TOsHuKOTubRR+dGJtD8RTev876JJHANq+KNb+3f9D8nQjNtplkAPcNISIKCl8S7vcSjuPcU58PRVEURVFOOvTlQ1EURVGUtqIvH4qiKIqitJWTzufDd9EGy30IYsLuXCsJ2yXTfJC2QuljwJH+EJGYuWdfD2oEpDPGHlevz+2PwWXYiYjSabTxcS0NaWvnVW80ZDy60Lxgdjz5zFzuV6all8+McuZCspxJdDtCrjtyRLp7PJ8LV/RzRNj7uU24Luy8Ud+MAynZUgsLSWPWDZ6XgaJqzfRJIIQ2+1oT7+mzseUVse4W8xEKYBHZnimri38FaqIPuH9I0BZ6JTYf23gh2ZfVqvGJkdLrlYqxbZdKaC+WOgXcJhyvoyaI4xjfgNfy+SgVzDwtFPEexHxHakHUprCEJoibNOXZIsqb12KmnfMWPvPuw6hVka1mW8fRBD5XNG3mZTIsUiQwPZV8DdeeXAH9OhKu0csIEa5b8YS5bi4n0jc08XzfHnM+NIJrUYH5zzQbAVGG86lRM+1TKeNnZ8iMg5CYT8Ej1CrmpovJgk8LPaDOHtTZCEI6d1z/Emydd8W6nRG+EhXm1yC1KlIp449hBYVeiPAZ8pi/YDyVgbIG8wcZHloEZSX2HWSFsK5J4bsRYBO8pxfTZPAUBZaP8zkotJ64n5svfD6aTFK+swN9aWRqDMcz7VypYtnxQHc+FEVRFEVpK8f08nH77bfTueeeS6lUilKpFK1Zs4Z++MMftsqr1SqtX7+eurq6KJFI0HXXXXeE4qaiKIqiKKc2x2R2GRoaoltvvZWWLl1Kvu/TN7/5Tbr66qvp6aefprPPPptuvPFG+sEPfkD33HMPpdNp2rBhA1177bX005/+9LhVeHgQM8VGmURuOIThUrUybn1ys4Mttq15VldpggmIz/LMn2IXnSanTPhUXWQbLLP6FMRWWamK282Nhvuqx0REDR4iK81QDpp6gsxc4InaunVzXV/msbVEqCuTKQ6KUM4wC1OLRvD+4SMyzs4nwGxo1PGZ6yILsRdn8tQhDP/jO8FSXtgXZhe+pSuS/lKpasoCNo6t/t5+OI8wM0Muh2GNPJzVbcj7m3NfhNraYnv1iMEGHzaHlgiTPiL0lo1nmfWyycyBNWHOyubRlOGy+jVE2tR4fO6wdkk+a57biQoTTcjMk6HT0FRgCbNHjoUj5vK4jR5Jmv6JdOHcq1SwveJsrOfy+M+TxcLlgzaaUgLMfFIu4jyQ5uJC0dQhIWT1Hcu0Zf8AmmTGD2KfdHebujohkd00ZJ5rZhb7x3Xxs50ZMyaqItQ26LNtfJF1ON2FbZeluWkyk/DgwBCUxeNogqix1BRBKQNuzz33M929cB6JGbmF/CyGcfMM240Khp1mOlBG3nJM+4SFDHmJhcx6QhYdlBCE+Sguvn09luohLNJ2WNzUJEz2lsi4XS2Z9ScgsqWnmPx7RMy1hjDPNthpQphcjwfH9PLxnve8B85vueUWuv322+nxxx+noaEh+sY3vkF33XUXveMd7yAiojvuuIOWL19Ojz/+OF1yySXHr9aKoiiKopy0vG6fD9d16e6776ZSqURr1qyhbdu2UaPRoLVr17Y+s2zZMhoZGaEtW7bMeZ1arUb5fB5+FEVRFEV563LMLx/PPfccJRIJCofD9IlPfILuvfdeOuuss2hsbIwcx6FMJgOf7+vro7GxsTmvt2nTJkqn062f4eHhOT+rKIqiKMrJzzGH2p555pn0zDPPUC6Xo+985zu0bt06euSRR153BW666SbauHFj6zyfz8/7AiLTnvOwI1/Y29IZDLtKzBgbl0z9zs1dnjCEh4WkO7eM7R09BGU8LLYhbPgNZjerCT+Opov39ObxQeHvjDJ8VvpqWCzltC3M8D57knoD7eABEXrmsPBanqaaiCjGw51FW0VEfwWDRyevLkNtZUhxsTC3kDMPC5Zt1xS+CbydZRkPL5NdIGXtUyz8Tj5jMmn6XYarcn8QHl5NdGSINfdfOSJUnJ0GhI+HDKPm41mObX7O0wG82jmXpLbsow9dl3C/pLCUUGf+Bv290i8Awwh5NGBGyIc3iqZvZ/MYWjs7iXXvS5r7+EIuO8J8DOJJrOvEjBmTxQKOpUgc+2By1vgiOF14nYhlxkgiJUJiq+KzvaY++Sw+10inWe8qZUw1USvj2KpVzdhqCj+pIPPjci1s80wGQ5ExSQTC/erKRVGfAvoTNZhfQyqDIaFl5tMgx2R+BvsyGjP16+pCP45y0fi2RMP4VZjsQCn2esU8t0zZ0NFtQpxrdWxXvhKUcii578Sw7WIsJL0ycxjKAsx3zgvg2O4QMg31iKmf1Y3jt8yew63jGLXFmh+PmbHWPIb0I0fLMb98OI5DS5YsISKilStX0pNPPklf+cpX6P3vfz/V63XKZrOw+zE+Pk79/f1zXO3ni51cABVFURRFeevyS7/OeJ5HtVqNVq5cSaFQiDZv3twq27lzJ+3fv5/WrFnzy95GURRFUZS3CMe083HTTTfRVVddRSMjI1QoFOiuu+6ihx9+mH70ox9ROp2mj33sY7Rx40bq7OykVCpFn/zkJ2nNmjUa6aIoiqIoSotjevmYmJigD33oQ3T48GFKp9N07rnn0o9+9CP6tV/7NSIi+tKXvkS2bdN1111HtVqNrrzySvra1752XCvsCXskT/0ubfYRoTnR12v0OVzhjyHt7RxpMy9kmX1SulywX0jtDG6nDwibPffNICLyWPl85nNpW7dEDLjLpH+lxgQxuWGpJRKwse3iUXOeimN8eDhghlFEpKYOS92R4NHJq9vCxlgV8r7cd+KINpB+MAwpNc7/VmqCcD0TX4wBW/g48PrK9Nz8ujWh/cJt1jK9vXxmGPtHjB9zfzleZX3m8/ng9ZFl8jr8XPqZyPP5CDKzfaOJfxeJmDlbKqPktR3E/nIcNg6j2HZcxl64ilAhh7oWnXEzJk47DWW/syWzbuSy6HdUq5uxFRSaQ/UG9rvPJPCFCZ8CEfMcuRzeIx7H+sSZj4wvNrIrVfO3Pb04JtwK9m05z3wwhAx4M2CeORwT84COniCbM3KGemIOcznzoBiHzYZZq6tCy6lSFdorvmmvpuwD5tsXSmagrCDS3TeYTHtUyKsH2DwIBvArtcK0cRqe0NxIoxw+/06IJHCNrdXMemcJv77ZMUxvH44bH5CY8Cvx2XdAtYb+Z1IHqiNsBmZBpFo4HhzTy8c3vvGNecsjkQjddtttdNttt/1SlVIURVEU5a2L5nZRFEVRFKWtnHxZbcX2HN/Sni+MkogoFjHbY8MDmDWQy0PLMM8j9ghZHY6wiPCyIwvnLJPP5bEQ4iNNBfwYy474LNtatIVJhmfhDIdx77erG8PbknGzvRsWppMwk4cOCHNJUMirB45SXv21+pJfV5po5gtTliYZeV0Ov668B5GQmGdbw/KafIzK6/D6SHNJVGRpns/swvvyiNBaKXnPTGHSlMLb9bVMKfxctut8pi+Jw0KTHQfDIcfHzfZ3IILhmMlOrHuDhY8GxMzkJrTZLG7Nd4hQTp8N2VoT50yJhaxW67gVnYiZrXI5qkoiKWhHh5lPoQh+ulg0dZ+dwnmwoAfHRKXCMgsnsWx2xmyrDw1ixGGtjBWKLzZb9aMiH1eCmRlqwqxh+bitPx8+m9Mhud70L4Bzl31WrgXdPWbtlvMpX0QzVdNl5nWx5vLUHEEL50xchGqXmUlvdgzDYHv6B1vHAWE+j7JQaUeYa2wb78mzc4cSaF6rl42kgy2+kMKJNF6Xzb3pKZSU5/Ndzv2pwxgozTOJpzuw7scD3flQFEVRFKWt6MuHoiiKoihtRV8+FEVRFEVpK5Z/LDrIbSCfz1M6nabPfvazqnyqKIqiKCcJtVqNbr31VsrlcpRKpeb9rO58KIqiKIrSVvTlQ1EURVGUtqIvH4qiKIqitBV9+VAURVEUpa3oy4eiKIqiKG3lTadw+ovgG5mAS1EURVGUNy+/+N4+miDaN12o7YEDB2h4ePhEV0NRFEVRlNfB6OgoDQ0NzfuZN93Lh+d5dOjQIfJ9n0ZGRmh0dPQ144VPRfL5PA0PD2v7zIG2z/xo+8yPts/8aPvMzancNr7vU6FQoMHBwVfJh4W86cwutm3T0NAQ5fN5IiJKpVKnXAceC9o+86PtMz/aPvOj7TM/2j5zc6q2TTqdfu0PkTqcKoqiKIrSZvTlQ1EURVGUtvKmffkIh8P0p3/6p5rfZQ60feZH22d+tH3mR9tnfrR95kbb5uh40zmcKoqiKIry1uZNu/OhKIqiKMpbE335UBRFURSlrejLh6IoiqIobUVfPhRFURRFaSv68qEoiqIoSlt507583HbbbbRo0SKKRCK0evVq2rp164muUtvZtGkTXXTRRZRMJqm3t5euueYa2rlzJ3ymWq3S+vXrqaurixKJBF133XU0Pj5+gmp8Yrn11lvJsiy64YYbWr871dvn4MGD9Lu/+7vU1dVF0WiUVqxYQU899VSr3Pd9+sIXvkADAwMUjUZp7dq1tGvXrhNY4/bhui7dfPPNtHjxYopGo3T66afTn//5n0NSrFOpfR599FF6z3veQ4ODg2RZFt13331QfjRtMTMzQ9dffz2lUinKZDL0sY99jIrFYhuf4o1jvvZpNBr0mc98hlasWEHxeJwGBwfpQx/6EB06dAiu8VZun2PGfxNy9913+47j+P/4j//oP//88/7v//7v+5lMxh8fHz/RVWsrV155pX/HHXf427dv95955hn/N37jN/yRkRG/WCy2PvOJT3zCHx4e9jdv3uw/9dRT/iWXXOJfeumlJ7DWJ4atW7f6ixYt8s8991z/U5/6VOv3p3L7zMzM+AsXLvQ//OEP+0888YT/yiuv+D/60Y/83bt3tz5z6623+ul02r/vvvv8n/3sZ/573/tef/HixX6lUjmBNW8Pt9xyi9/V1eXff//9/p49e/x77rnHTyQS/le+8pXWZ06l9vn3f/93//Of/7z/3e9+1yci/95774Xyo2mLd73rXf55553nP/744/5PfvITf8mSJf4HP/jBNj/JG8N87ZPNZv21a9f63/72t/0dO3b4W7Zs8S+++GJ/5cqVcI23cvscK2/Kl4+LL77YX79+fevcdV1/cHDQ37Rp0wms1YlnYmLCJyL/kUce8X3/5wM+FAr599xzT+szL774ok9E/pYtW05UNdtOoVDwly5d6j/44IP+r/7qr7ZePk719vnMZz7jX3755XOWe57n9/f3+3/913/d+l02m/XD4bD/L//yL+2o4gnl3e9+t//Rj34Ufnfttdf6119/ve/7p3b7yC/Xo2mLF154wSci/8knn2x95oc//KFvWZZ/8ODBttW9Hbzay5lk69atPhH5+/bt833/1Gqfo+FNZ3ap1+u0bds2Wrt2bet3tm3T2rVracuWLSewZieeXC5HRESdnZ1ERLRt2zZqNBrQVsuWLaORkZFTqq3Wr19P7373u6EdiLR9/u3f/o1WrVpFv/3bv029vb10wQUX0N///d+3yvfs2UNjY2PQPul0mlavXn1KtM+ll15KmzdvppdeeomIiH72s5/RY489RldddRURaftwjqYttmzZQplMhlatWtX6zNq1a8m2bXriiSfaXucTTS6XI8uyKJPJEJG2j+RNl9V2amqKXNelvr4++H1fXx/t2LHjBNXqxON5Ht1www102WWX0TnnnENERGNjY+Q4Tmtw/4K+vj4aGxs7AbVsP3fffTf993//Nz355JNHlJ3q7fPKK6/Q7bffThs3bqTPfe5z9OSTT9If/dEfkeM4tG7dulYbvNpcOxXa57Of/Szl83latmwZBQIBcl2XbrnlFrr++uuJiE759uEcTVuMjY1Rb28vlAeDQers7Dzl2qtardJnPvMZ+uAHP9jKbKvtg7zpXj6UV2f9+vW0fft2euyxx050Vd40jI6O0qc+9Sl68MEHKRKJnOjqvOnwPI9WrVpFf/mXf0lERBdccAFt376dvv71r9O6detOcO1OPP/6r/9K3/rWt+iuu+6is88+m5555hm64YYbaHBwUNtHed00Gg36nd/5HfJ9n26//fYTXZ03LW86s0t3dzcFAoEjIhLGx8epv7//BNXqxLJhwwa6//776cc//jENDQ21ft/f30/1ep2y2Sx8/lRpq23bttHExARdeOGFFAwGKRgM0iOPPEJf/epXKRgMUl9f3yndPgMDA3TWWWfB75YvX0779+8nImq1wak61/74j/+YPvvZz9IHPvABWrFiBf3e7/0e3XjjjbRp0yYi0vbhHE1b9Pf308TEBJQ3m02amZk5ZdrrFy8e+/btowcffLC160Gk7SN50718OI5DK1eupM2bN7d+53kebd68mdasWXMCa9Z+fN+nDRs20L333ksPPfQQLV68GMpXrlxJoVAI2mrnzp20f//+U6Kt3vnOd9Jzzz1HzzzzTOtn1apVdP3117eOT+X2ueyyy44IzX7ppZdo4cKFRES0ePFi6u/vh/bJ5/P0xBNPnBLtUy6XybZxCQwEAuR5HhFp+3COpi3WrFlD2WyWtm3b1vrMQw89RJ7n0erVq9te53bzixePXbt20X/+539SV1cXlJ/q7XMEJ9rj9dW4++67/XA47N95553+Cy+84H/84x/3M5mMPzY2dqKr1lb+4A/+wE+n0/7DDz/sHz58uPVTLpdbn/nEJz7hj4yM+A899JD/1FNP+WvWrPHXrFlzAmt9YuHRLr5/arfP1q1b/WAw6N9yyy3+rl27/G9961t+LBbz//mf/7n1mVtvvdXPZDL+9773Pf/ZZ5/1r7766rdsKKlk3bp1/oIFC1qhtt/97nf97u5u/9Of/nTrM6dS+xQKBf/pp5/2n376aZ+I/L/5m7/xn3766Va0xtG0xbve9S7/ggsu8J944gn/scce85cuXfqWCSWdr33q9br/3ve+1x8aGvKfeeYZWK9rtVrrGm/l9jlW3pQvH77v+3/7t3/rj4yM+I7j+BdffLH/+OOPn+gqtR0ietWfO+64o/WZSqXi/+Ef/qHf0dHhx2Ix/33ve59/+PDhE1fpE4x8+TjV2+f73/++f8455/jhcNhftmyZ/3d/93dQ7nmef/PNN/t9fX1+OBz23/nOd/o7d+48QbVtL/l83v/Upz7lj4yM+JFIxD/ttNP8z3/+8/BlcSq1z49//ONXXW/WrVvn+/7RtcX09LT/wQ9+0E8kEn4qlfI/8pGP+IVC4QQ8zfFnvvbZs2fPnOv1j3/849Y13srtc6xYvs/k/BRFURRFUd5g3nQ+H4qiKIqivLXRlw9FURRFUdqKvnwoiqIoitJW9OVDURRFUZS2oi8fiqIoiqK0FX35UBRFURSlrejLh6IoiqIobUVfPhRFURRFaSv68qEoiqIoSlvRlw9FURRFUdqKvnwoiqIoitJW/n/avCRkZ/OJwQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    plt.imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "image_iter = iter(train_loader)\n",
    "images, _ = next(image_iter)\n",
    "imshow(torchvision.utils.make_grid(images[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eab2da15-dde1-4280-91ee-3504541053b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "926bdf96-0b0d-465a-9e55-cb238a727bfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "from collections import OrderedDict\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "250d4b5d-dcb2-4898-8c53-531b7ca7d07b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Res2NetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, scales=4, stride=1, bottleneck_width=4):\n",
    "        super(Res2NetBlock, self).__init__()\n",
    "        self.scales = scales\n",
    "        self.bottleneck_width = bottleneck_width\n",
    "        \n",
    "        # 计算每个尺度的卷积通道数\n",
    "        self.d = out_channels // scales\n",
    "        \n",
    "        # 定义每个尺度的卷积\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(scales):\n",
    "            in_ch = in_channels if i == 0 else self.d\n",
    "            out_ch = self.d if i < scales - 1 else out_channels\n",
    "            self.convs.append(\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "            )\n",
    "        \n",
    "        # 批归一化和激活\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 计算每个尺度的卷积\n",
    "        out = [conv(x) for conv in self.convs]\n",
    "        \n",
    "        # 合并各个尺度的输出\n",
    "        out = torch.cat(out, dim=1)\n",
    "        \n",
    "        # 批归一化和激活\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "867b2989-449c-417b-8706-fab3ed9c42b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Res2Net(nn.Module):\n",
    "    def __init__(self, num_classes=10, scales=4, bottleneck_width=4):\n",
    "        super(Res2Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # 更正层次之间通道数的配置\n",
    "        self.layer1 = self._make_layer(64, 64, scales, bottleneck_width, num_blocks=3)\n",
    "        self.layer2 = self._make_layer(64, 128, scales, bottleneck_width, num_blocks=4, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, scales, bottleneck_width, num_blocks=6, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, scales, bottleneck_width, num_blocks=3, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, scales, bottleneck_width, num_blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(Res2NetBlock(in_channels, out_channels, scales, stride, bottleneck_width))\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(Res2NetBlock(out_channels, out_channels, scales, 1, bottleneck_width))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a56841d3-ec96-46ed-960c-589b2c68fec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = Res2Net(num_classes=10, scales=4, bottleneck_width=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f47726ab-71b5-4a21-8faa-b5c8848bce11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "399fe48d-d423-4166-9629-813cf61e12ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if device == 'cuda':\n",
    "    net = nn.DataParallel(net)\n",
    "    # 当计算图不会改变的时候（每次输入形状相同，模型不改变）的情况下可以提高性能，反之则降低性能\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e57446b5-9524-4b27-94d9-8c7dd0c6429e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    acc = 100.*correct/total\n",
    "    loss = train_loss / batch_idx\n",
    "    print('Epoch: %d, train loss: %.6f, acc: %.3f%% (%d/%d)' % (epoch, loss, acc, correct, total))\n",
    "    return loss\n",
    "# Evaluation\n",
    "def test(epoch):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    acc = 100. * correct / total\n",
    "    print('Epoch:Test Loss: %.6f | Acc: %.3f%% (%d/%d)' % (avg_loss, acc, correct, total))\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4528cf8b-f1b0-4445-8206-41eb8d983c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Res2Net Block\n",
    "class Res2NetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, scales=4, stride=1):\n",
    "        super(Res2NetBlock, self).__init__()\n",
    "        self.scales = scales\n",
    "        self.d = out_channels // scales  # 每个尺度的通道数\n",
    "        self.convs = nn.ModuleList()\n",
    "\n",
    "        # 定义每个尺度的卷积\n",
    "        for i in range(scales):\n",
    "            in_ch = in_channels if i == 0 else self.d\n",
    "            out_ch = self.d if i < scales - 1 else out_channels\n",
    "            self.convs.append(\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "            )\n",
    "\n",
    "        # 批归一化和激活\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = [conv(x) for conv in self.convs]\n",
    "        out = torch.cat(out, dim=1)  # 将多个尺度的输出拼接起来\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# 网络主体结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, scales=4):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = Res2NetBlock(3, 6, scales)  # 使用Res2NetBlock替代原始卷积\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = Res2NetBlock(6, 16, scales)  # 使用Res2NetBlock替代原始卷积\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 使用Res2Net块输出并激活\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 使用Res2Net块输出并激活\n",
    "        x = torch.flatten(x, 1)  # 展平，除了batch维度\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 创建网络实例\n",
    "net = Net(scales=4).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457e75d4-272b-4000-b782-1563fc575abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "x = torch.randn(2, 3, 32, 32).to(device)\n",
    "y = net(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "968ea5b0-8bf8-4ccc-a452-cb6b1e6075e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 0, train loss: 1.790485, acc: 33.716% (16858/50000)\n",
      "Epoch:Test Loss: 1.390998 | Acc: 48.500% (4850/10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:1013: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train loss: 1.240648, acc: 54.906% (27453/50000)\n",
      "Epoch:Test Loss: 1.429329 | Acc: 50.230% (5023/10000)\n",
      "Epoch: 2, train loss: 1.024425, acc: 63.442% (31721/50000)\n",
      "Epoch:Test Loss: 1.170635 | Acc: 59.110% (5911/10000)\n",
      "Epoch: 3, train loss: 0.910826, acc: 67.510% (33755/50000)\n",
      "Epoch:Test Loss: 1.050989 | Acc: 64.320% (6432/10000)\n",
      "Epoch: 4, train loss: 0.826312, acc: 70.826% (35413/50000)\n",
      "Epoch:Test Loss: 1.210453 | Acc: 63.300% (6330/10000)\n",
      "Epoch: 5, train loss: 0.748749, acc: 73.788% (36894/50000)\n",
      "Epoch:Test Loss: 0.831807 | Acc: 71.270% (7127/10000)\n",
      "Epoch: 6, train loss: 0.718241, acc: 75.140% (37570/50000)\n",
      "Epoch:Test Loss: 0.944607 | Acc: 69.720% (6972/10000)\n",
      "Epoch: 7, train loss: 0.688455, acc: 76.098% (38049/50000)\n",
      "Epoch:Test Loss: 1.294273 | Acc: 62.270% (6227/10000)\n",
      "Epoch: 8, train loss: 0.665275, acc: 77.022% (38511/50000)\n",
      "Epoch:Test Loss: 1.130460 | Acc: 64.500% (6450/10000)\n",
      "Epoch: 9, train loss: 0.651522, acc: 77.612% (38806/50000)\n",
      "Epoch:Test Loss: 0.936901 | Acc: 69.710% (6971/10000)\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 10, train loss: 0.477203, acc: 83.614% (41807/50000)\n",
      "Epoch:Test Loss: 0.472962 | Acc: 83.580% (8358/10000)\n",
      "Epoch: 11, train loss: 0.430585, acc: 85.274% (42637/50000)\n",
      "Epoch:Test Loss: 0.463245 | Acc: 83.880% (8388/10000)\n",
      "Epoch: 12, train loss: 0.410503, acc: 85.808% (42904/50000)\n",
      "Epoch:Test Loss: 0.441154 | Acc: 84.770% (8477/10000)\n",
      "Epoch: 13, train loss: 0.395961, acc: 86.340% (43170/50000)\n",
      "Epoch:Test Loss: 0.431389 | Acc: 85.130% (8513/10000)\n",
      "Epoch: 14, train loss: 0.382006, acc: 86.932% (43466/50000)\n",
      "Epoch:Test Loss: 0.437311 | Acc: 85.140% (8514/10000)\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 15, train loss: 0.350598, acc: 88.076% (44038/50000)\n",
      "Epoch:Test Loss: 0.406264 | Acc: 86.350% (8635/10000)\n",
      "Epoch: 16, train loss: 0.341225, acc: 88.320% (44160/50000)\n",
      "Epoch:Test Loss: 0.399562 | Acc: 86.510% (8651/10000)\n",
      "Epoch: 17, train loss: 0.338538, acc: 88.496% (44248/50000)\n",
      "Epoch:Test Loss: 0.401696 | Acc: 86.520% (8652/10000)\n",
      "Epoch: 18, train loss: 0.336334, acc: 88.592% (44296/50000)\n",
      "Epoch:Test Loss: 0.396756 | Acc: 86.770% (8677/10000)\n",
      "Epoch: 19, train loss: 0.331609, acc: 88.766% (44383/50000)\n",
      "Epoch:Test Loss: 0.397249 | Acc: 86.820% (8682/10000)\n",
      "Epoch 00019: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 20, train loss: 0.328780, acc: 88.800% (44400/50000)\n",
      "Epoch:Test Loss: 0.398054 | Acc: 86.570% (8657/10000)\n",
      "Epoch: 21, train loss: 0.329306, acc: 88.898% (44449/50000)\n",
      "Epoch:Test Loss: 0.394733 | Acc: 86.750% (8675/10000)\n",
      "Epoch: 22, train loss: 0.326427, acc: 88.888% (44444/50000)\n",
      "Epoch:Test Loss: 0.396325 | Acc: 86.600% (8660/10000)\n",
      "Epoch: 23, train loss: 0.325937, acc: 88.812% (44406/50000)\n",
      "Epoch:Test Loss: 0.397645 | Acc: 86.680% (8668/10000)\n",
      "Epoch 00023: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch: 24, train loss: 0.330924, acc: 88.652% (44326/50000)\n",
      "Epoch:Test Loss: 0.393795 | Acc: 86.820% (8682/10000)\n",
      "Epoch: 25, train loss: 0.325539, acc: 88.840% (44420/50000)\n",
      "Epoch:Test Loss: 0.394918 | Acc: 86.770% (8677/10000)\n",
      "Epoch: 26, train loss: 0.327236, acc: 88.694% (44347/50000)\n",
      "Epoch:Test Loss: 0.394547 | Acc: 86.740% (8674/10000)\n",
      "Epoch: 27, train loss: 0.328231, acc: 88.834% (44417/50000)\n",
      "Epoch:Test Loss: 0.393082 | Acc: 86.840% (8684/10000)\n",
      "Epoch 00027: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch: 28, train loss: 0.326999, acc: 88.852% (44426/50000)\n",
      "Epoch:Test Loss: 0.395257 | Acc: 86.610% (8661/10000)\n",
      "Epoch: 29, train loss: 0.328693, acc: 88.762% (44381/50000)\n",
      "Epoch:Test Loss: 0.394131 | Acc: 86.770% (8677/10000)\n",
      "Epoch: 30, train loss: 0.325374, acc: 88.882% (44441/50000)\n",
      "Epoch:Test Loss: 0.396561 | Acc: 86.660% (8666/10000)\n",
      "Epoch: 31, train loss: 0.326522, acc: 88.768% (44384/50000)\n",
      "Epoch:Test Loss: 0.395588 | Acc: 86.740% (8674/10000)\n",
      "Epoch 00031: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch: 32, train loss: 0.326322, acc: 88.780% (44390/50000)\n",
      "Epoch:Test Loss: 0.395556 | Acc: 86.700% (8670/10000)\n",
      "Epoch: 33, train loss: 0.328511, acc: 88.796% (44398/50000)\n",
      "Epoch:Test Loss: 0.394591 | Acc: 86.640% (8664/10000)\n",
      "Epoch: 34, train loss: 0.326051, acc: 88.928% (44464/50000)\n",
      "Epoch:Test Loss: 0.396589 | Acc: 86.740% (8674/10000)\n",
      "Epoch: 35, train loss: 0.326627, acc: 88.868% (44434/50000)\n",
      "Epoch:Test Loss: 0.395164 | Acc: 86.790% (8679/10000)\n",
      "Epoch 00035: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch: 36, train loss: 0.326614, acc: 89.004% (44502/50000)\n",
      "Epoch:Test Loss: 0.394849 | Acc: 86.750% (8675/10000)\n",
      "Epoch: 37, train loss: 0.324741, acc: 88.976% (44488/50000)\n",
      "Epoch:Test Loss: 0.398735 | Acc: 86.650% (8665/10000)\n",
      "Epoch: 38, train loss: 0.327721, acc: 88.740% (44370/50000)\n",
      "Epoch:Test Loss: 0.394546 | Acc: 86.730% (8673/10000)\n",
      "Epoch: 39, train loss: 0.327447, acc: 88.824% (44412/50000)\n",
      "Epoch:Test Loss: 0.394494 | Acc: 86.760% (8676/10000)\n",
      "Epoch: 40, train loss: 0.326860, acc: 88.822% (44411/50000)\n",
      "Epoch:Test Loss: 0.395377 | Acc: 86.680% (8668/10000)\n",
      "Epoch: 41, train loss: 0.327384, acc: 88.926% (44463/50000)\n",
      "Epoch:Test Loss: 0.395485 | Acc: 86.610% (8661/10000)\n",
      "Epoch: 42, train loss: 0.324815, acc: 88.772% (44386/50000)\n",
      "Epoch:Test Loss: 0.395352 | Acc: 86.820% (8682/10000)\n",
      "Epoch: 43, train loss: 0.329149, acc: 88.800% (44400/50000)\n",
      "Epoch:Test Loss: 0.393978 | Acc: 86.720% (8672/10000)\n",
      "Epoch: 44, train loss: 0.324023, acc: 88.946% (44473/50000)\n",
      "Epoch:Test Loss: 0.395873 | Acc: 86.680% (8668/10000)\n",
      "Epoch: 45, train loss: 0.325732, acc: 88.800% (44400/50000)\n",
      "Epoch:Test Loss: 0.395543 | Acc: 86.780% (8678/10000)\n",
      "Epoch: 46, train loss: 0.324863, acc: 88.828% (44414/50000)\n",
      "Epoch:Test Loss: 0.395371 | Acc: 86.790% (8679/10000)\n",
      "Epoch: 47, train loss: 0.328490, acc: 88.764% (44382/50000)\n",
      "Epoch:Test Loss: 0.395449 | Acc: 86.720% (8672/10000)\n",
      "Epoch: 48, train loss: 0.326787, acc: 88.864% (44432/50000)\n",
      "Epoch:Test Loss: 0.394227 | Acc: 86.750% (8675/10000)\n",
      "Epoch: 49, train loss: 0.326693, acc: 88.854% (44427/50000)\n",
      "Epoch:Test Loss: 0.395423 | Acc: 86.580% (8658/10000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Res2Net Block\n",
    "class Res2NetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, scale=4, width=26):\n",
    "        super(Res2NetBlock, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.width = width\n",
    "        self.mid_channels = width * scale\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, self.mid_channels, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.mid_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "        for i in range(scale - 1):\n",
    "            self.convs.append(nn.Conv2d(width, width, kernel_size=3, padding=1, bias=False))\n",
    "            self.bns.append(nn.BatchNorm2d(width))\n",
    "\n",
    "        self.conv3 = nn.Conv2d(self.mid_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        split_size = self.width\n",
    "        spx = torch.split(out, split_size, 1)\n",
    "        ys = []\n",
    "        ys.append(spx[0])\n",
    "        for i in range(1, self.scale):\n",
    "            ys.append(self.relu(self.bns[i-1](self.convs[i-1](spx[i])) + ys[i-1]))\n",
    "\n",
    "        out = torch.cat(ys, 1)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# Res2Net Model\n",
    "class Res2Net(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10, scale=4, width=26):\n",
    "        super(Res2Net, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.scale = scale\n",
    "        self.width = width\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "        # 初始化权重\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample, scale=self.scale, width=self.width))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels, scale=self.scale, width=self.width))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 数据预处理\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Res2Net(Res2NetBlock, [3, 3, 3], num_classes=10, scale=4, width=16).to(device)\n",
    "lr = 1e-1\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, threshold=0.1, patience=3, verbose=True)\n",
    "\n",
    "# 训练和测试函数\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_loss += loss.item()\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    acc = 100.*correct/total\n",
    "    loss = train_loss / batch_idx\n",
    "    print('Epoch: %d, train loss: %.6f, acc: %.3f%% (%d/%d)' % (epoch, loss, acc, correct, total))\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    avg_loss = test_loss / len(testloader)\n",
    "    acc = 100. * correct / total\n",
    "    print('Epoch:Test Loss: %.6f | Acc: %.3f%% (%d/%d)' % (avg_loss, acc, correct, total))\n",
    "    return avg_loss\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(50):\n",
    "    train(epoch)\n",
    "    test_loss =test(epoch)\n",
    "    scheduler.step(test_loss, epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b722b6-5af3-44ac-8366-156d747c3df5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 1e-1\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, threshold=0.1, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d25edbf-bd96-47d4-a48a-dbe9214575a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_epoch: 0\n"
     ]
    }
   ],
   "source": [
    "load_model = False\n",
    "if load_model:\n",
    "    checkpoint = torch.load('./checkpoint/cnn.ckpt')\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "else:\n",
    "    start_epoch = 0\n",
    "print('start_epoch: %s' % start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a90ee-8c52-4b14-a659-c43fcc3c3c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1ca025-1542-4e43-b559-eaab5102dbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c816a8-252b-4575-bdaa-04b3974f2e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c07f6a1-ccda-4315-8aff-b8e529f6abea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce45675e-23c2-4eec-b48d-367baf63c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    对于浅层网络，我们使用基本的Block\n",
    "    基础块没有维度压缩，所以expansion=1\n",
    "    \"\"\"\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        # 如果输入输出维度不等，则使用1x1卷积层来改变维度\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * out_channels),\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = torch.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "257cc8b5-7a49-486e-b05e-180a305fe257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicBlock(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (shortcut): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([2, 128, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "basic_block = BasicBlock(64, 128)\n",
    "print(basic_block)\n",
    "x = torch.randn(2, 64, 32, 32)\n",
    "y = basic_block(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83ca3b22-3751-41b2-9fd9-9ca0440e85a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    对于深层网络，我们使用BottleNeck，论文中提出其拥有近似的计算复杂度，但能节省很多资源\n",
    "    zip_channels: 压缩后的维数，最后输出的维数是 expansion * zip_channels\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_channels, zip_channels, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        out_channels = self.expansion * zip_channels\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, zip_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(zip_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(zip_channels, zip_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(zip_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(zip_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = torch.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68422a38-da3f-4b4e-9fe3-7975d672b9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (shortcut): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([2, 512, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "bottleneck = Bottleneck(256, 128)\n",
    "print(bottleneck)\n",
    "x = torch.randn(2, 256, 32, 32)\n",
    "y = bottleneck(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "090c4395-44f5-4d2d-bb16-9c3e25856877",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    不同的ResNet架构都是统一的一层特征提取、四层残差，不同点在于每层残差的深度。\n",
    "    对于cifar10，feature map size的变化如下：\n",
    "    (32, 32, 3) -> [Conv2d] -> (32, 32, 64) -> [Res1] -> (32, 32, 64) -> [Res2] \n",
    " -> (16, 16, 128) -> [Res3] -> (8, 8, 256) ->[Res4] -> (4, 4, 512) -> [AvgPool] \n",
    " -> (1, 1, 512) -> [Reshape] -> (512) -> [Linear] -> (10)\n",
    "    \"\"\"\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        # cifar10经过上述结构后，到这里的feature map size是 4 x 4 x 512 x expansion\n",
    "        # 所以这里用了 4 x 4 的平均池化\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=4)\n",
    "        self.classifer = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        # 第一个block要进行降采样\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            # 如果是Bottleneck Block的话需要对每层输入的维度进行压缩，压缩后再增加维数\n",
    "            # 所以每层的输入维数也要跟着变\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c859d304-0c20-4360-93f3-f75a7a429cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3,4,6,3])\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3,4,6,3])\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3,4,23,3])\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3,8,36,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae1b6077-3a62-4ac7-b063-b2abb0a6c6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "  (classifer): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = ResNet18().to(device)\n",
    "print(net)\n",
    "if device == 'cuda':\n",
    "    net = nn.DataParallel(net)\n",
    "    # 当计算图不会改变的时候（每次输入形状相同，模型不改变）的情况下可以提高性能，反之则降低性能\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "020dc291-c281-4028-b775-e42495273ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "x = torch.randn(2, 3, 32, 32).to(device)\n",
    "y = net(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16c22c2b-ca7a-40aa-bc35-1d955f22c9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-1\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, threshold=0.1, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6705ad0a-a66d-4ec8-a2a7-9d9eadc5194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % (epoch))\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        if batch_idx % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.6f |  Acc: %.3f%% (%d/%d)' %\n",
    "                  (epoch + 1, batch_idx + 1, train_loss, 100.*correct/total, correct, total))\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed481ddd-aa49-45e8-a528-cba75d6503d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def test(epoch):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    acc = 100. * correct / total\n",
    "    print('Test Loss: %.6f | Acc: %.3f%% (%d/%d)' % (avg_loss, acc, correct, total))\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e31deeef-bcbe-4dc2-995a-37734ba06218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_epoch: 0\n"
     ]
    }
   ],
   "source": [
    "load_model = False\n",
    "if load_model:\n",
    "    checkpoint = torch.load('./checkpoint/res18.ckpt')\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "else:\n",
    "    start_epoch = 0\n",
    "print('start_epoch: %s' % start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1aa353eb-765c-4902-975b-cfaa4579ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    acc = 100.*correct/total\n",
    "    loss = train_loss / batch_idx\n",
    "    print('Epoch: %d, train loss: %.6f, acc: %.3f%% (%d/%d)' % (epoch, loss, acc, correct, total))\n",
    "    return loss\n",
    "# Evaluation\n",
    "def test(epoch):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    acc = 100. * correct / total\n",
    "    print('Test Loss: %.6f | Acc: %.3f%% (%d/%d)' % (avg_loss, acc, correct, total))\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a859ebfe-a497-4078-9be8-372aa3ff2546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 1.837289, acc: 34.844% (17422/50000)\n",
      "Test Loss: 1.394777 | Acc: 47.890% (4789/10000)\n",
      "Epoch 0 | Train Loss: 1.837289 | Test Loss: 1.394777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:1350: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train loss: 1.287498, acc: 53.294% (26647/50000)\n",
      "Test Loss: 1.288672 | Acc: 53.550% (5355/10000)\n",
      "Epoch 1 | Train Loss: 1.287498 | Test Loss: 1.288672\n",
      "Epoch: 2, train loss: 1.026461, acc: 63.580% (31790/50000)\n",
      "Test Loss: 0.983380 | Acc: 65.000% (6500/10000)\n",
      "Epoch 2 | Train Loss: 1.026461 | Test Loss: 0.983380\n",
      "Epoch: 3, train loss: 0.829200, acc: 70.724% (35362/50000)\n",
      "Test Loss: 0.911941 | Acc: 68.850% (6885/10000)\n",
      "Epoch 3 | Train Loss: 0.829200 | Test Loss: 0.911941\n",
      "Epoch: 4, train loss: 0.704869, acc: 75.322% (37661/50000)\n",
      "Test Loss: 0.699549 | Acc: 75.550% (7555/10000)\n",
      "Epoch 4 | Train Loss: 0.704869 | Test Loss: 0.699549\n",
      "Epoch: 5, train loss: 0.589245, acc: 79.520% (39760/50000)\n",
      "Test Loss: 0.793440 | Acc: 73.570% (7357/10000)\n",
      "Epoch 5 | Train Loss: 0.589245 | Test Loss: 0.793440\n",
      "Epoch: 6, train loss: 0.521570, acc: 82.082% (41041/50000)\n",
      "Test Loss: 0.642697 | Acc: 78.470% (7847/10000)\n",
      "Epoch 6 | Train Loss: 0.521570 | Test Loss: 0.642697\n",
      "Epoch: 7, train loss: 0.470782, acc: 83.838% (41919/50000)\n",
      "Test Loss: 0.668122 | Acc: 77.720% (7772/10000)\n",
      "Epoch 7 | Train Loss: 0.470782 | Test Loss: 0.668122\n",
      "Epoch: 8, train loss: 0.439607, acc: 84.792% (42396/50000)\n",
      "Test Loss: 0.651176 | Acc: 78.210% (7821/10000)\n",
      "Epoch 8 | Train Loss: 0.439607 | Test Loss: 0.651176\n",
      "Epoch: 9, train loss: 0.244856, acc: 91.882% (45941/50000)\n",
      "Test Loss: 0.368708 | Acc: 87.310% (8731/10000)\n",
      "Epoch 9 | Train Loss: 0.244856 | Test Loss: 0.368708\n",
      "Epoch: 10, train loss: 0.173602, acc: 94.376% (47188/50000)\n",
      "Test Loss: 0.358711 | Acc: 88.140% (8814/10000)\n",
      "Epoch 10 | Train Loss: 0.173602 | Test Loss: 0.358711\n",
      "Epoch: 11, train loss: 0.139748, acc: 95.520% (47760/50000)\n",
      "Test Loss: 0.364923 | Acc: 88.350% (8835/10000)\n",
      "Epoch 11 | Train Loss: 0.139748 | Test Loss: 0.364923\n",
      "Epoch: 12, train loss: 0.106041, acc: 96.692% (48346/50000)\n",
      "Test Loss: 0.376749 | Acc: 88.210% (8821/10000)\n",
      "Epoch 12 | Train Loss: 0.106041 | Test Loss: 0.376749\n",
      "Epoch: 13, train loss: 0.080390, acc: 97.642% (48821/50000)\n",
      "Test Loss: 0.383384 | Acc: 87.820% (8782/10000)\n",
      "Epoch 13 | Train Loss: 0.080390 | Test Loss: 0.383384\n",
      "Epoch: 14, train loss: 0.051842, acc: 98.724% (49362/50000)\n",
      "Test Loss: 0.365769 | Acc: 88.740% (8874/10000)\n",
      "Epoch 14 | Train Loss: 0.051842 | Test Loss: 0.365769\n",
      "Epoch: 15, train loss: 0.044634, acc: 98.972% (49486/50000)\n",
      "Test Loss: 0.371239 | Acc: 88.530% (8853/10000)\n",
      "Epoch 15 | Train Loss: 0.044634 | Test Loss: 0.371239\n",
      "Epoch: 16, train loss: 0.041718, acc: 99.048% (49524/50000)\n",
      "Test Loss: 0.376502 | Acc: 88.590% (8859/10000)\n",
      "Epoch 16 | Train Loss: 0.041718 | Test Loss: 0.376502\n",
      "Epoch: 17, train loss: 0.038985, acc: 99.194% (49597/50000)\n",
      "Test Loss: 0.374953 | Acc: 88.800% (8880/10000)\n",
      "Epoch 17 | Train Loss: 0.038985 | Test Loss: 0.374953\n",
      "Epoch: 18, train loss: 0.035201, acc: 99.296% (49648/50000)\n",
      "Test Loss: 0.376657 | Acc: 88.860% (8886/10000)\n",
      "Epoch 18 | Train Loss: 0.035201 | Test Loss: 0.376657\n",
      "Epoch: 19, train loss: 0.035189, acc: 99.300% (49650/50000)\n",
      "Test Loss: 0.372862 | Acc: 88.720% (8872/10000)\n",
      "Epoch 19 | Train Loss: 0.035189 | Test Loss: 0.372862\n",
      "Epoch: 20, train loss: 0.035536, acc: 99.326% (49663/50000)\n",
      "Test Loss: 0.375373 | Acc: 88.640% (8864/10000)\n",
      "Epoch 20 | Train Loss: 0.035536 | Test Loss: 0.375373\n",
      "Epoch: 21, train loss: 0.034961, acc: 99.282% (49641/50000)\n",
      "Test Loss: 0.380897 | Acc: 88.490% (8849/10000)\n",
      "Epoch 21 | Train Loss: 0.034961 | Test Loss: 0.380897\n",
      "Epoch: 22, train loss: 0.034261, acc: 99.358% (49679/50000)\n",
      "Test Loss: 0.371059 | Acc: 89.080% (8908/10000)\n",
      "Epoch 22 | Train Loss: 0.034261 | Test Loss: 0.371059\n",
      "Epoch: 23, train loss: 0.034986, acc: 99.340% (49670/50000)\n",
      "Test Loss: 0.373634 | Acc: 88.660% (8866/10000)\n",
      "Epoch 23 | Train Loss: 0.034986 | Test Loss: 0.373634\n",
      "Epoch: 24, train loss: 0.034278, acc: 99.330% (49665/50000)\n",
      "Test Loss: 0.372760 | Acc: 89.070% (8907/10000)\n",
      "Epoch 24 | Train Loss: 0.034278 | Test Loss: 0.372760\n",
      "Epoch: 25, train loss: 0.034064, acc: 99.368% (49684/50000)\n",
      "Test Loss: 0.374505 | Acc: 88.410% (8841/10000)\n",
      "Epoch 25 | Train Loss: 0.034064 | Test Loss: 0.374505\n",
      "Epoch: 26, train loss: 0.035032, acc: 99.302% (49651/50000)\n",
      "Test Loss: 0.374729 | Acc: 88.620% (8862/10000)\n",
      "Epoch 26 | Train Loss: 0.035032 | Test Loss: 0.374729\n",
      "Epoch: 27, train loss: 0.034968, acc: 99.336% (49668/50000)\n",
      "Test Loss: 0.373637 | Acc: 88.520% (8852/10000)\n",
      "Epoch 27 | Train Loss: 0.034968 | Test Loss: 0.373637\n",
      "Epoch: 28, train loss: 0.034640, acc: 99.328% (49664/50000)\n",
      "Test Loss: 0.379038 | Acc: 88.790% (8879/10000)\n",
      "Epoch 28 | Train Loss: 0.034640 | Test Loss: 0.379038\n",
      "Epoch: 29, train loss: 0.034167, acc: 99.360% (49680/50000)\n",
      "Test Loss: 0.366423 | Acc: 88.830% (8883/10000)\n",
      "Epoch 29 | Train Loss: 0.034167 | Test Loss: 0.366423\n",
      "Epoch: 30, train loss: 0.033733, acc: 99.400% (49700/50000)\n",
      "Test Loss: 0.372179 | Acc: 88.740% (8874/10000)\n",
      "Epoch 30 | Train Loss: 0.033733 | Test Loss: 0.372179\n",
      "Epoch: 31, train loss: 0.034458, acc: 99.336% (49668/50000)\n",
      "Test Loss: 0.369636 | Acc: 88.860% (8886/10000)\n",
      "Epoch 31 | Train Loss: 0.034458 | Test Loss: 0.369636\n",
      "Epoch: 32, train loss: 0.033832, acc: 99.374% (49687/50000)\n",
      "Test Loss: 0.378170 | Acc: 88.630% (8863/10000)\n",
      "Epoch 32 | Train Loss: 0.033832 | Test Loss: 0.378170\n",
      "Epoch: 33, train loss: 0.033396, acc: 99.372% (49686/50000)\n",
      "Test Loss: 0.369289 | Acc: 88.730% (8873/10000)\n",
      "Epoch 33 | Train Loss: 0.033396 | Test Loss: 0.369289\n",
      "Epoch: 34, train loss: 0.035317, acc: 99.312% (49656/50000)\n",
      "Test Loss: 0.381876 | Acc: 88.530% (8853/10000)\n",
      "Epoch 34 | Train Loss: 0.035317 | Test Loss: 0.381876\n",
      "Epoch: 35, train loss: 0.034589, acc: 99.312% (49656/50000)\n",
      "Test Loss: 0.381519 | Acc: 88.340% (8834/10000)\n",
      "Epoch 35 | Train Loss: 0.034589 | Test Loss: 0.381519\n",
      "Epoch: 36, train loss: 0.034725, acc: 99.344% (49672/50000)\n",
      "Test Loss: 0.376781 | Acc: 88.680% (8868/10000)\n",
      "Epoch 36 | Train Loss: 0.034725 | Test Loss: 0.376781\n",
      "Epoch: 37, train loss: 0.034449, acc: 99.350% (49675/50000)\n",
      "Test Loss: 0.371032 | Acc: 88.910% (8891/10000)\n",
      "Epoch 37 | Train Loss: 0.034449 | Test Loss: 0.371032\n",
      "Epoch: 38, train loss: 0.034633, acc: 99.328% (49664/50000)\n",
      "Test Loss: 0.383114 | Acc: 88.420% (8842/10000)\n",
      "Epoch 38 | Train Loss: 0.034633 | Test Loss: 0.383114\n",
      "Epoch: 39, train loss: 0.034832, acc: 99.316% (49658/50000)\n",
      "Test Loss: 0.375574 | Acc: 88.840% (8884/10000)\n",
      "Epoch 39 | Train Loss: 0.034832 | Test Loss: 0.375574\n",
      "Epoch: 40, train loss: 0.034224, acc: 99.332% (49666/50000)\n",
      "Test Loss: 0.370038 | Acc: 88.800% (8880/10000)\n",
      "Epoch 40 | Train Loss: 0.034224 | Test Loss: 0.370038\n",
      "Epoch: 41, train loss: 0.035122, acc: 99.312% (49656/50000)\n",
      "Test Loss: 0.379030 | Acc: 88.400% (8840/10000)\n",
      "Epoch 41 | Train Loss: 0.035122 | Test Loss: 0.379030\n",
      "Epoch: 42, train loss: 0.033503, acc: 99.362% (49681/50000)\n",
      "Test Loss: 0.376153 | Acc: 88.630% (8863/10000)\n",
      "Epoch 42 | Train Loss: 0.033503 | Test Loss: 0.376153\n",
      "Epoch: 43, train loss: 0.034680, acc: 99.336% (49668/50000)\n",
      "Test Loss: 0.382057 | Acc: 88.310% (8831/10000)\n",
      "Epoch 43 | Train Loss: 0.034680 | Test Loss: 0.382057\n",
      "Epoch: 44, train loss: 0.034174, acc: 99.366% (49683/50000)\n",
      "Test Loss: 0.372565 | Acc: 88.790% (8879/10000)\n",
      "Epoch 44 | Train Loss: 0.034174 | Test Loss: 0.372565\n",
      "Epoch: 45, train loss: 0.036052, acc: 99.302% (49651/50000)\n",
      "Test Loss: 0.372702 | Acc: 88.850% (8885/10000)\n",
      "Epoch 45 | Train Loss: 0.036052 | Test Loss: 0.372702\n",
      "Epoch: 46, train loss: 0.034664, acc: 99.296% (49648/50000)\n",
      "Test Loss: 0.372160 | Acc: 88.780% (8878/10000)\n",
      "Epoch 46 | Train Loss: 0.034664 | Test Loss: 0.372160\n",
      "Epoch: 47, train loss: 0.033945, acc: 99.370% (49685/50000)\n",
      "Test Loss: 0.374332 | Acc: 88.770% (8877/10000)\n",
      "Epoch 47 | Train Loss: 0.033945 | Test Loss: 0.374332\n",
      "Epoch: 48, train loss: 0.034613, acc: 99.298% (49649/50000)\n",
      "Test Loss: 0.374750 | Acc: 88.660% (8866/10000)\n",
      "Epoch 48 | Train Loss: 0.034613 | Test Loss: 0.374750\n",
      "Epoch: 49, train loss: 0.034063, acc: 99.352% (49676/50000)\n",
      "Test Loss: 0.372426 | Acc: 88.760% (8876/10000)\n",
      "Epoch 49 | Train Loss: 0.034063 | Test Loss: 0.372426\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, 50):\n",
    "    train_loss = train(epoch)\n",
    "    test_loss = test(epoch)\n",
    "    print('Epoch %d | Train Loss: %.6f | Test Loss: %.6f' % (epoch, train_loss, test_loss))\n",
    "\n",
    "    scheduler.step(test_loss, epoch=epoch)  # 如果是 ReduceLROnPlateau 类型的 scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b451638-6f93-4414-8684-2c5dfc309e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch, 50):\n",
    "    loss = train(epoch)\n",
    "    print('Total loss: %.6f' % loss)\n",
    "    start_epoch = epoch\n",
    "    scheduler.step(loss, epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce695163-3401-4822-a05b-2a4e7b4476a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "if save_model:\n",
    "    state = {\n",
    "        'net': net.state_dict(),\n",
    "        'epoch': epoch,\n",
    "    }\n",
    "    os.makedirs('checkpoint', exist_ok=True)\n",
    "    torch.save(state, './checkpoint/res18.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3b8fda8-9339-4bee-9f93-b45674d27e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:    cat  ship   car plane\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "Accuracy of plane : 93 %\n",
      "Accuracy of   car : 96 %\n",
      "Accuracy of  bird : 84 %\n",
      "Accuracy of   cat : 83 %\n",
      "Accuracy of  deer : 93 %\n",
      "Accuracy of   dog : 87 %\n",
      "Accuracy of  frog : 94 %\n",
      "Accuracy of horse : 90 %\n",
      "Accuracy of  ship : 91 %\n",
      "Accuracy of truck : 96 %\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "images = images[:4]\n",
    "labels = labels[:4]\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "outputs = net(images.to(device))\n",
    "_, predicted = torch.max(outputs.cpu(), 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5af8171-f2bc-485a-8359-b10dcad2a752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
